# -*- coding: utf-8 -*-
"""AgiFransdanaProyek2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19kRmq-601_m2fQG8z9RpwS7b6757WKRP

PROYEK AKHIR MACHINE LEARNING INTERMEDIATE
-----
Nama  : Agi Fransdana

Username : agi_fransdana_HCmZ

Email : agif270602@gmail.com
"""

# TensorFlow dan Keras untuk membuat dan melatih model
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Library visualisasi dan analisis data
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os

# Scikit-learn untuk evaluasi model
from sklearn.metrics import classification_report, confusion_matrix

# TensorFlow Lite
import tensorflow.lite as tflite
import requests
import json

print(tf.__version__)

!kaggle datasets download -d harshvardhan21/sign-language-detection-using-images

!unzip sign-language-detection-using-images.zip -d sign-language-detection-using-images

base_dir = "sign-language-detection-using-images/data"

def count_images_in_directory(directory):
    image_extensions = ('.png', '.jpg', '.jpeg')
    total_images = 0
    label_counts = {}

    for root, _, files in os.walk(directory):
        count = len([file for file in files if file.lower().endswith(image_extensions)])

        if count > 0:
            label = os.path.basename(root)
            label_counts[label] = count
            total_images += count

    return total_images, label_counts

base_dir = "sign-language-detection-using-images/data"

total_images, label_counts = count_images_in_directory(base_dir)
print(f"Total gambar dalam dataset: {total_images}")
print("\nJumlah gambar per kelas/label:")
for label, count in label_counts.items():
    print(f"{label}: {count} gambar")

import random
from PIL import Image

def generate_random_sizes(min_size, max_size, num_sizes):
    sizes = []
    for _ in range(num_sizes):
        width = random.randint(min_size, max_size)
        height = random.randint(min_size, max_size)
        sizes.append((width, height))
    return sizes

def resize_images_in_directory(directory, min_size, max_size):
    image_extensions = ('.png', '.jpg', '.jpeg')

    for root, _, files in os.walk(directory):
        for file in files:
            if file.lower().endswith(image_extensions):
                img_path = os.path.join(root, file)

                try:
                    img = Image.open(img_path)
                    width = random.randint(min_size, max_size)
                    height = random.randint(min_size, max_size)
                    img_resized = img.resize((width, height), Image.ANTIALIAS)
                    img_resized.save(img_path)
                    print(f"Gambar {file} diresize menjadi {width}x{height}")

                except Exception as e:
                    print(f"Error resizing image {file}: {e}")
min_size = 120
max_size = 255
base_dir = "sign-language-detection-using-images/data"
resize_images_in_directory(base_dir, min_size, max_size)

def count_images_in_directory(directory):
    image_extensions = ('.png', '.jpg', '.jpeg')
    total_images = 0
    label_counts = {}

    print(f"Memeriksa direktori: {directory}")

    for root, dirs, files in os.walk(directory):
        print(f"Memeriksa folder: {root}")
        count = len([file for file in files if file.lower().endswith(image_extensions)])

        if count > 0:
            label = os.path.basename(root)
            label_counts[label] = count
            total_images += count

    return total_images, label_counts

base_dir = "sign-language-detection-using-images/data"

total_images, label_counts = count_images_in_directory(base_dir)

print(f"Total gambar dalam dataset: {total_images}")
print("\nJumlah gambar per kelas/label:")
for label, count in label_counts.items():
    print(f"{label}: {count} gambar")

root_dir = Path('sign-language-detection-using-images/data')

image_paths = list(root_dir.rglob('*.jpg')) + list(root_dir.rglob('*.JPG')) + \
              list(root_dir.rglob('*.png')) + list(root_dir.rglob('*.PNG'))

labels = [Path(filepath).parent.name for filepath in image_paths]

df_images = pd.DataFrame({
    'Filepath': image_paths,
    'Label': labels
})

df_images.head()

# Visualisasikan distribusi label dengan barplot
plt.figure(figsize=(18, 5))

sns.barplot(x=label_distribution.index, y=label_distribution.values, palette='rocket', hue=label_distribution.index, dodge=False, legend=False)

plt.title('Jumlah Gambar per Label', fontsize=15)
plt.xlabel('Label', fontsize=12)
plt.ylabel('Jumlah', fontsize=12)
plt.xticks(rotation=45)
plt.show()

sample_images = df_images.sample(n=15)

fig, axes = plt.subplots(3, 5, figsize=(9, 9))
for ax, (i, row) in zip(axes.flatten(), sample_images.iterrows()):
    img = Image.open(row['Filepath'])
    ax.imshow(img)
    ax.set_title(row['Label'])
    ax.axis('off')
plt.tight_layout()
plt.show()

# Fungsi untuk mengubah gambar menjadi array
def load_image_as_array(filepath, target_size=(64, 64)):
    img = Image.open(filepath)
    img = img.resize(target_size)
    return np.array(img)

# Konversi semua gambar menjadi array
X_data = np.array([load_image_as_array(filepath) for filepath in df_images['Filepath']])
y_data = np.array(df_images['Label'])

# Cek bentuk (shape) dari data
print(f'Bentuk X: {X_data.shape}')
print(f'Bentuk y: {y_data.shape}')

# Normalisasi data gambar
X_data = X_data.astype('float32') / 255.0

from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

encoder = LabelEncoder()
y_data_encoded = encoder.fit_transform(y_data)
y_data_one_hot = to_categorical(y_data_encoded)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_data, y_data_one_hot, test_size=0.2, random_state=42)

print(f'Bentuk X_train: {X_train.shape}')
print(f'Bentuk X_test: {X_test.shape}')
print(f'Bentuk y_train: {y_train.shape}')
print(f'Bentuk y_test: {y_test.shape}')

from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, BatchNormalization,Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2

model = Sequential()
model.add(Input(shape=(64, 64, 3)))
model.add(Conv2D(8, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(16, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(GlobalAveragePooling2D())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(35, activation='softmax'))
model.compile(optimizer=Adam(learning_rate=1e-4),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

from tensorflow.keras.callbacks import ReduceLROnPlateau

early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)
model_checkpoint = ModelCheckpoint('model.keras', monitor='val_loss', save_best_only=True)

history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=15,
    callbacks=[early_stopping, reduce_lr, model_checkpoint]
)

loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

labels = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F',
          'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',
          'U', 'V', 'W', 'X', 'Y', 'Z']

y_test_labels = np.argmax(y_test, axis=1)
y_pred = model.predict(X_test)
y_pred_labels = np.argmax(y_pred, axis=1)

conf_matrix = confusion_matrix(y_test_labels, y_pred_labels)

plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels)
plt.title('Confusion Matrix', fontsize=16)
plt.xlabel('Predicted Labels', fontsize=14)
plt.ylabel('True Labels', fontsize=14)
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

class_report = classification_report(y_test_labels, y_pred_labels, target_names=labels)
print("Classification Report:")
print(class_report)

# Buat struktur folder
submission_dir = 'submission'
tfjs_model_dir = os.path.join(submission_dir, 'tfjs_model')
tflite_model_dir = os.path.join(submission_dir, 'tflite')
saved_model_dir = os.path.join(submission_dir, 'saved_model')

os.makedirs(tfjs_model_dir, exist_ok=True)
os.makedirs(tflite_model_dir, exist_ok=True)
os.makedirs(saved_model_dir, exist_ok=True)

import tensorflow as tf

saved_model_dir = 'submission/saved_model'
model.export(saved_model_dir)

tflite_model_dir = 'submission/tflite'

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with open(os.path.join(tflite_model_dir, 'model.tflite'), 'wb') as f:
    f.write(tflite_model)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
with open(os.path.join(tflite_model_dir, 'model.tflite'), 'wb') as f:
    f.write(tflite_model)

import subprocess

tfjs_model_dir = 'submission/tfjs_model'
os.makedirs(tfjs_model_dir, exist_ok=True)
subprocess.run(['tensorflowjs_converter', '--input_format=tf_saved_model',
                '--output_format=tfjs_graph_model', saved_model_dir, tfjs_model_dir])

label_file_path = os.path.join(tflite_model_dir, 'label.txt')

class_names = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F',
                'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',
                'U', 'V', 'W', 'X', 'Y', 'Z']

with open(label_file_path, 'w') as f:
    f.write('\n'.join(class_names))

!zip -r submission.zip submission

import shutil
zip_file_path = '/content/submission.zip'
destination_path = '/content/submission_saved.zip'
shutil.copy(zip_file_path, destination_path)
print(f"File ZIP telah disimpan di {destination_path}")

import tflite_runtime.interpreter as tflite
from PIL import Image

model_path = 'submission/tflite/model.tflite'
interpreter = tflite.Interpreter(model_path=model_path)
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

img_path = 'depositphotos_7426187-stock-photo-hand-sign-language-alphabet.jpg'
img = Image.open(img_path).resize((input_details[0]['shape'][1], input_details[0]['shape'][2]))
img_array = np.array(img, dtype=np.float32)
img_array = np.expand_dims(img_array, axis=0) / 255.0

interpreter.set_tensor(input_details[0]['index'], img_array)
interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
print("Output:", output_data)

!pip freeze > requirements.txt