# -*- coding: utf-8 -*-
"""Untitled42.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rYSaNeygUUKc4O1-sFe4Ikhwr1YBPlz-

# 1. IMPORTING LIBRARY

Dalam proyek ini, digunakan beberapa library utama: **Pandas** untuk pengolahan data, **NumPy** untuk operasi numerik, **Matplotlib** dan **Seaborn** untuk visualisasi, serta **Zipfile** dan **OS** untuk mengelola file dan direktori.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import zipfile
import os

"""Mengunduh dataset student-performance-factors dari kaggle menggunakan Kaggle API."""

!kaggle datasets download -d lainguyn123/student-performance-factors

"""Selanjutnya, mengekstrak file ZIP yang diunduh ke folder bernama student-performance-factors."""

!unzip student-performance-factors -d student-performance-factors

"""# 2. DATA LOADING"""

df = pd.read_csv("student-performance-factors/StudentPerformanceFactors.csv")
df

"""Dari data diatas terlihat 20 Variabel dengan jumlah sebanyak 6607

# 3. DATA UNDERSTANDING

A. Melihat jumlah masing-masing variabel beserta tipenya
"""

df.info()

"""Dari hasil di atas, dapat dilihat bahwa:

Kolom bertipe object:

Kolom yang berisi data kategori atau teks:

Parental_Involvement, Access_to_Resources, Extracurricular_Activities, Motivation_Level, Internet_Access, Family_Income, Teacher_Quality, School_Type, Peer_Influence, Learning_Disabilities, Parental_Education_Level, Distance_from_Home, Gender.

Kolom bertipe int64:

Kolom yang berisi data numerik tanpa desimal:

Hours_Studied, Attendance, Sleep_Hours, Previous_Scores, Tutoring_Sessions, Physical_Activity, Exam_Score.

B. Deskripsi Variabel

Berikut merupakan arti dari masing masing variabel beserta nilai-nilainya.

Variabel | Keterangan | Nilai
------- | ----------- | --------
Hourss_Studied | Jumlah Jam yang dihabiskan siswa untuk belajar | 1-44
Attendance | Tingkat kehadiran siswa | 60-100
Parental_Involvement | Tingkat keterlibatan orang tua dalam pendidikan siswa | Low, Medium, High
Access_to_Resources | Ketersediaan sumber daya pendidikan untuk siswa | Low, Medium, High
Extracurricular_Activities | Partisipasi siswa dalam kegiatan ekstrakurikuler | Yes, No
Sleep_Hours | Jumlah jam tidur siswa setiap malam | 4-10
Previous_Scores | Skor siswa pada tes sebelumnya | 50-100
Motivation_Level | Tingkat motivasi siswa untuk belajar | Low, Medium, High
Internet_Access | Ketersediaan akses internet untuk siswa | Yes, No
Tutoring_Sessions | Jumlah sesi les tambahan yang diikuti siswa | 0-8
Family_Income | Tingkat pendapatan keluarga siswa | Low, Medium, High
Teacher_Quality | Kualitas pengajaran guru | Low, Medium, High
School_Type | Jenis sekolah tempat siswa belajar | Public, Private
Peer_Influence | Pengaruh teman sebaya terhadap siswa |  Negative, Neutral, Positive
Physical_Activity | Frekuensi aktivitas fisik siswa dalam seminggu | 0-6
Learning_Disabilities | Indikasi apakah siswa memiliki kesulitan belajar | No, Yes
Parental_Education_Level |Tingkat pendidikan tertinggi yang dicapai oleh orang tua | High School, College, Postgraduate.
Distance_from_Home | Jarak antara rumah siswa dan sekolah | Near, Moderate, Far
Gender | Jenis kelamin siswa | Male, Female
Exam_Score | Nilai  ujian siswa | 55-101

C. Deskripsi Statistik Data
"""

df.describe()

"""# 4. DATA CLEANING

A. Menangani Missing Value

Langkah pertama dalam Data Cleaning adalah memeriksa nilai 0 pada setiap kolom
"""

missing_values = df.isnull().sum()
print("Jumlah nilai yang hilang di setiap kolom:\n", missing_values)

"""Terlihat bahwa ada beberapa kolom yang bernilai 0. oleh karena itu, pada baris yang terdapat nilai 0 akan dihapus."""

missing_rows = df.loc[(df[["Teacher_Quality", "Parental_Education_Level", "Distance_from_Home"]].isnull().any(axis=1))]
df = df.loc[(df[["Teacher_Quality", "Parental_Education_Level", "Distance_from_Home"]].notnull().all(axis=1))]
df.shape

"""Setelah menghapus pada baris yang terdapat nilai 0, sehingga terdapat 6378 baris

B. Memeriksa Outlier

langkah kedua dalam Data Cleaning adalah Memeriksa Outlier pada kolom-kolom Numerik
"""

sns.boxplot(x = df["Hours_Studied"])

"""Terdapat beberapa nilai outlier pada kolom Hours_Studied, yaitu nilai yang jauh di luar rentang distribusi utama"""

sns.boxplot(x = df["Attendance"])

"""Bisa dilihat visualisasi diatas, tidak ditemukan nilai outlier pada kolom Attendance"""

sns.boxplot(x = df["Sleep_Hours"])

"""Bisa dilihat visualisasi diatas, tidak ditemukan nilai outlier pada kolom Attendance"""

sns.boxplot(x = df["Previous_Scores"])

"""Bisa dilihat visualisasi diatas, tidak ditemukan nilai outlier pada kolom Attendance"""

sns.boxplot(x = df["Tutoring_Sessions"])

"""Bisa dilihat visualisasi diatas, terdapat beberapa nilai outlier pada kolom Tutoring_Studied"""

sns.boxplot(x = df["Physical_Activity"])

"""Bisa dilihat visualisasi diatas, tidak ditemukan nilai outlier pada kolom Attendance"""

sns.boxplot(x = df["Exam_Score"])

"""Pada kolom Exam_Score, terdapat beberapa nilai outlier

Terlihat bahwa terdapat outlier pada kolom Hours_studied, Tutoring_Sessions, dan Exam_Score. dalam kasus ini, kita akan menghapus outlier menggunakan teknik **Interquartile Range (IQR)**. IQR dihitung sebagai:

IQR=Q3−Q1

dengan:

Batas Bawah:
Q1−1.5*IQR

Batas Atas:
Q3+1.5*IQR

Outlier adalah nilai yang berada di luar batas ini, dan akan dihapus dari dataset.
"""

numeric_columns = df.select_dtypes(include = ["number"]).columns

Q1 = df[numeric_columns].quantile(0.25)
Q3 = df[numeric_columns].quantile(0.75)
IQR = Q3 - Q1

df = df[~((df[numeric_columns] < (Q1 - 1.5 * IQR)) |
         (df[numeric_columns] > (Q3 + 1.5 * IQR))).any(axis =1)]

df.shape

"""C. MEMERIKSA DATA DUPLIKAT

Langkah selanjutnya ialah memeriksa apakah terdapat data duplikat pada dataset ini.
"""

df.duplicated().sum()

"""Berdasarkan hasil diatas, tidak data duplikat dalam dataset ini."""

df.info()

"""Setelah proses data cleaning, jumlah total baris data yang tersisa adalah 5.836.

# 5. EXPLORATORY DATA ANALYSIS

## A. Univariate Analysis

pada kode dibawah Membagi kolom-kolom menjadi kolom numerikal dan kolom kategorikal
"""

numerical_features = ["Hours_Studied", "Attendance", "Sleep_Hours", "Previous_Scores", "Tutoring_Sessions", "Physical_Activity", "Exam_Score"]
categorical_features = ["Parental_Involvement", "Access_to_Resources", "Extracurricular_Activities", "Motivation_Level", "Internet_Access", "Family_Income", "Teacher_Quality", "School_Type", "Peer_Influence", "Learning_Disabilities", "Parental_Education_Level", "Distance_from_Home", "Gender"]

"""1. Barplot pertama Memeriksa Fitur Parental_Involvement"""

feature = categorical_features[0]
count_parental_involvement = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_parental_involvement = pd.DataFrame({"Jumlah Sampel": count_parental_involvement, "Persentase": percent.round(1)})
print(df_parental_involvement)
count_parental_involvement.plot(kind="bar", title=feature)
plt.xlabel("Parental_Involvement")
plt.show()

"""Sebagian besar sampel Parental Involvement berada pada tingkat Medium dengan jumlah 2992 yang mewakili 51,3% dari total data.

Pada kode dibawah ini digunakan untuk membuat diagram pie berdasarkan data pada variabel count_parental_involvement:

1. plt.pie(): Membuat diagram pie dengan:
  - Nilai dari count_parental_involvement sebagai ukuran.
  - Label berdasarkan indeksnya.
  - Menampilkan persentase pada tiap bagian dengan format %1.1f%%.
  - Memutar diagram mulai dari sudut 90 derajat (startangle=90).

2. plt.title(): Memberikan judul pada diagram pie.
3. plt.legend(): Menambahkan legenda di sisi kiri diagram.

4. plt.show(): Menampilkan diagram pie.
"""

plt.figure(figsize=(8, 6))
plt.pie(
    count_parental_involvement,
    labels=count_parental_involvement.index,
    autopct="%1.1f%%",
    startangle=90
)
plt.title(f"Pie Chart of {feature}")
plt.legend(title=feature, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.show()

"""2. Barplot kedua memerikasa fitur Access_to_Resources"""

feature = categorical_features[1]
count_Access_to_Resources = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_Access_to_Resources = pd.DataFrame({"Jumlah Sampel": count_Access_to_Resources, "Persentase": percent.round(1)})
print(df_Access_to_Resources)
count_Access_to_Resources.plot(kind="bar", title=feature)
plt.xlabel("Access to Resources")
plt.show()

"""Sebagian besar sampel Access_to_Resources berada pada tingkat Medium dengan jumlah 2963 yang mewakili 50,3% dari total data.

Pada kode dibawah ini digunakan untuk membuat diagram pie berdasarkan data pada variabel count_Access_to_Resources:

1. plt.pie(): Membuat diagram pie dengan:
  - Nilai dari count_Access_to_Resources sebagai ukuran.
  - Label berdasarkan indeksnya.
  - Menampilkan persentase pada tiap bagian dengan format %1.1f%%.
  - Memutar diagram mulai dari sudut 90 derajat (startangle=90).

2. plt.title(): Memberikan judul pada diagram pie.
3. plt.legend(): Menambahkan legenda di sisi kiri diagram.

4. plt.show(): Menampilkan diagram pie.
"""

plt.figure(figsize=(8, 6))
plt.pie(
    count_Access_to_Resources,
    labels=count_Access_to_Resources.index,
    autopct="%1.1f%%",
    startangle=90
)
plt.title(f"Pie Chart of {feature}")
plt.legend(title=feature, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.show()

"""3. Barplot ketiga Memeriksa Fitur Extracurricular Activities"""

feature = categorical_features[2]
count_Extracurricular_Activities = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_Extracurricular_Activities = pd.DataFrame({"Jumlah Sampel": count_Extracurricular_Activities, "Persentase": percent.round(1)})
print(df_Extracurricular_Activities)
count_Extracurricular_Activities.plot(kind="bar", title=feature)
plt.xlabel("Extracurricular Activities")
plt.show()

"""siswa yang mengikuti kegiatan ekstrakurikuler memiliki jumlah yang lebih banyak dari pada siswa yang tidak mengikuti ekstrakurikuler.

Pada kode dibawah ini digunakan untuk membuat diagram pie berdasarkan data pada variabel count_Extracurricular:

1. plt.pie(): Membuat diagram pie dengan:
  - Nilai dari count_Access_to_Resources sebagai ukuran.
  - Label berdasarkan indeksnya.
  - Menampilkan persentase pada tiap bagian dengan format %1.1f%%.
  - Memutar diagram mulai dari sudut 90 derajat (startangle=90).

2. plt.title(): Memberikan judul pada diagram pie.
3. plt.legend(): Menambahkan legenda di sisi kiri diagram.

4. plt.show(): Menampilkan diagram pie.
"""

plt.figure(figsize=(8, 6))
plt.pie(
    count_Extracurricular_Activities,
    labels=count_Extracurricular_Activities.index,
    autopct="%1.1f%%",
    startangle=90
)
plt.title(f"Pie Chart of {feature}")
plt.legend(title=feature, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.show()

"""4. Barplot keempat Memeriksa Fitur Motivation Level"""

feature = categorical_features[3]
count_Motivation_Level = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_Motivation_Level = pd.DataFrame({"Jumlah Sampel": count_Motivation_Level, "Persentase": percent.round(1)})
print(df_Motivation_Level)
count_Motivation_Level.plot(kind="bar", title=feature)
plt.xlabel("Motivation Level")
plt.show()

"""Sebagian besar sampel Motivation Level berada pada tingkat Medium dengan jumlah 2967 yang mewakili 50,8% dari total data.

Pada kode dibawah ini digunakan untuk membuat diagram pie berdasarkan data pada variabel count_Motivation_Level:

1. plt.pie(): Membuat diagram pie dengan:
  - Nilai dari count_Motivation_Level sebagai ukuran.
  - Label berdasarkan indeksnya.
  - Menampilkan persentase pada tiap bagian dengan format %1.1f%%.
  - Memutar diagram mulai dari sudut 90 derajat (startangle=90).

2. plt.title(): Memberikan judul pada diagram pie.
3. plt.legend(): Menambahkan legenda di sisi kiri diagram.

4. plt.show(): Menampilkan diagram pie.
"""

plt.figure(figsize=(8, 6))
plt.pie(
    count_Motivation_Level,
    labels=count_Motivation_Level.index,
    autopct="%1.1f%%",
    startangle=90
)
plt.title(f"Pie Chart of {feature}")
plt.legend(title=feature, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.show()

"""5. Barplot kelima Memeriksa Fitur Internet Access"""

feature = categorical_features[4]
count_Internet_Access = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_Internet_Access = pd.DataFrame({"Jumlah Sampel": count_Internet_Access, "Persentase": percent.round(1)})
print(df_Internet_Access)
count_Internet_Access.plot(kind="bar", title=feature)
plt.xlabel("Internet Access")
plt.show()

"""siswa yang memiliki akses internet memiliki jumlah yang lebih banyak dari pada siswa yang tidak memiliki akses internet.

Pada kode dibawah ini digunakan untuk membuat diagram pie berdasarkan data pada variabel count_Internet_Access:

1. plt.pie(): Membuat diagram pie dengan:
  - Nilai dari count_Internet_Access sebagai ukuran.
  - Label berdasarkan indeksnya.
  - Menampilkan persentase pada tiap bagian dengan format %1.1f%%.
  - Memutar diagram mulai dari sudut 90 derajat (startangle=90).

2. plt.title(): Memberikan judul pada diagram pie.
3. plt.legend(): Menambahkan legenda di sisi kiri diagram.

4. plt.show(): Menampilkan diagram pie.
"""

plt.figure(figsize=(8, 6))
plt.pie(
    count_Internet_Access,
    labels=count_Internet_Access.index,
    autopct="%1.1f%%",
    startangle=90
)
plt.title(f"Pie Chart of {feature}")
plt.legend(title=feature, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.show()

"""6. Barplot keenam Memeriksa Fitur Family Income"""

feature = categorical_features[5]
count_Family_Income = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_Family_Income = pd.DataFrame({"Jumlah Sampel": count_Family_Income, "Persentase": percent.round(1)})
print(df_Family_Income)
count_Family_Income.plot(kind="bar", title=feature)
plt.xlabel("Family Income")
plt.show()

"""Sebagian besar sampel Family Income berada pada tingkat Medium dengan jumlah 2364 yang mewakili 40,5% dari total data.

Pada kode dibawah ini digunakan untuk membuat diagram pie berdasarkan data pada variabel count_Family_Income:

1. plt.pie(): Membuat diagram pie dengan:
  - Nilai dari count_Family_Income sebagai ukuran.
  - Label berdasarkan indeksnya.
  - Menampilkan persentase pada tiap bagian dengan format %1.1f%%.
  - Memutar diagram mulai dari sudut 90 derajat (startangle=90).

2. plt.title(): Memberikan judul pada diagram pie.
3. plt.legend(): Menambahkan legenda di sisi kiri diagram.

4. plt.show(): Menampilkan diagram pie.
"""

plt.figure(figsize=(8, 6))
plt.pie(
    count_Family_Income,
    labels=count_Family_Income.index,
    autopct="%1.1f%%",
    startangle=90
)
plt.title(f"Pie Chart of {feature}")
plt.legend(title=feature, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.show()

"""7. Barplot ketujuh Memeriksa Fitur Teacher Quality"""

feature = categorical_features[6]
count_Teacher_Quality = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_Teacher_Quality = pd.DataFrame({"Jumlah Sampel": count_Teacher_Quality, "Persentase": percent.round(1)})
print(df_Teacher_Quality)
count_Teacher_Quality.plot(kind="bar", title=feature)
plt.xlabel("Teacher Quality")
plt.show()

"""Sebagian besar sampel Persepsi siswa terhadap kualitas pengajaran guru berada pada tingkat Medium dengan jumlah 3499 yang mewakili 60% dari total data.

Pada kode dibawah ini digunakan untuk membuat diagram pie berdasarkan data pada variabel count_Teacher_Quality:

1. plt.pie(): Membuat diagram pie dengan:
  - Nilai dari count_Teacher_Quality sebagai ukuran.
  - Label berdasarkan indeksnya.
  - Menampilkan persentase pada tiap bagian dengan format %1.1f%%.
  - Memutar diagram mulai dari sudut 90 derajat (startangle=90).

2. plt.title(): Memberikan judul pada diagram pie.
3. plt.legend(): Menambahkan legenda di sisi kiri diagram.

4. plt.show(): Menampilkan diagram pie.
"""

plt.figure(figsize=(8, 6))
plt.pie(
    count_Teacher_Quality,
    labels=count_Teacher_Quality.index,
    autopct="%1.1f%%",
    startangle=90
)
plt.title(f"Pie Chart of {feature}")
plt.legend(title=feature, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.show()

"""8. Barplot kedelapan Memeriksa Fitur School Type"""

feature = categorical_features[7]
count_School_Type = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_School_Type = pd.DataFrame({"Jumlah Sampel": count_School_Type, "Persentase": percent.round(1)})
print(df_School_Type)
count_School_Type.plot(kind="bar", title=feature)
plt.xlabel("School Type")
plt.show()

"""School Type dengan kategori Public memiliki jumlah yang lebih banyak dari pada kategori Private.

Pada kode dibawah ini digunakan untuk membuat diagram pie berdasarkan data pada variabel count_parental_involvement:

1. plt.pie(): Membuat diagram pie dengan:
  - Nilai dari count_School_Type sebagai ukuran.
  - Label berdasarkan indeksnya.
  - Menampilkan persentase pada tiap bagian dengan format %1.1f%%.
  - Memutar diagram mulai dari sudut 90 derajat (startangle=90).

2. plt.title(): Memberikan judul pada diagram pie.
3. plt.legend(): Menambahkan legenda di sisi kiri diagram.

4. plt.show(): Menampilkan diagram pie.
"""

plt.figure(figsize=(8, 6))
plt.pie(
    count_School_Type,
    labels=count_School_Type.index,
    autopct="%1.1f%%",
    startangle=90
)
plt.title(f"Pie Chart of {feature}")
plt.legend(title=feature, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.show()

"""9. Barplot kesembilan Memeriksa Fitur Peer Influence"""

feature = categorical_features[8]
count_Peer_Influence = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_Peer_Influence = pd.DataFrame({"Jumlah Sampel": count_Peer_Influence, "Persentase": percent.round(1)})
print(df_Peer_Influence)
count_Peer_Influence.plot(kind="bar", title=feature)
plt.xlabel("Peer Influence")
plt.show()

"""sebagian besar sampel memiliki pengaruh teman yang positif atau netral, sementara pengaruh negatif relatif lebih kecil.

Pada kode dibawah ini digunakan untuk membuat diagram pie berdasarkan data pada variabel count_Peer_Influence:

1. plt.pie(): Membuat diagram pie dengan:
  - Nilai dari count_Peer_Influence sebagai ukuran.
  - Label berdasarkan indeksnya.
  - Menampilkan persentase pada tiap bagian dengan format %1.1f%%.
  - Memutar diagram mulai dari sudut 90 derajat (startangle=90).

2. plt.title(): Memberikan judul pada diagram pie.
3. plt.legend(): Menambahkan legenda di sisi kiri diagram.

4. plt.show(): Menampilkan diagram pie.
"""

plt.figure(figsize=(8, 6))
plt.pie(
    count_Peer_Influence,
    labels=count_Peer_Influence.index,
    autopct="%1.1f%%",
    startangle=90
)
plt.title(f"Pie Chart of {feature}")
plt.legend(title=feature, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.show()

"""10. Barplot pertama Memeriksa Fitur Learning Disabilities"""

feature = categorical_features[9]
count_Learning_Disabilities = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_Learning_Disabilities = pd.DataFrame({"Jumlah Sampel": count_Learning_Disabilities, "Persentase": percent.round(1)})
print(df_Learning_Disabilities)
count_Learning_Disabilities.plot(kind="bar", title=feature)
plt.xlabel("Learning Disabilities")
plt.show()



"""Sebagian besar sampel tidak memiliki gangguan belajar.

Pada kode dibawah ini digunakan untuk membuat diagram pie berdasarkan data pada variabel count_Learning_Disablities:

1. plt.pie(): Membuat diagram pie dengan:
  - Nilai dari count_Learning_Disabilities sebagai ukuran.
  - Label berdasarkan indeksnya.
  - Menampilkan persentase pada tiap bagian dengan format %1.1f%%.
  - Memutar diagram mulai dari sudut 90 derajat (startangle=90).

2. plt.title(): Memberikan judul pada diagram pie.
3. plt.legend(): Menambahkan legenda di sisi kiri diagram.

4. plt.show(): Menampilkan diagram pie.
"""

plt.figure(figsize=(8, 6))
plt.pie(
    count_Learning_Disabilities,
    labels=count_Learning_Disabilities.index,
    autopct="%1.1f%%",
    startangle=90
)
plt.title(f"Pie Chart of {feature}")
plt.legend(title=feature, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.show()

"""11. Barplot sebelas Memeriksa Fitur Parental Education Level"""

feature = categorical_features[10]
count_Parental_Education_Level = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_Parental_Education_Level = pd.DataFrame({"Jumlah Sampel": count_Parental_Education_Level, "Persentase": percent.round(1)})
print(df_Parental_Education_Level)
count_Parental_Education_Level.plot(kind="bar", title=feature)
plt.xlabel("Parental Education Level")
plt.show()

"""Sebagian besar orang tua memiliki tingkat pendidikan setara High School, sementara tingkat Postgraduate merupakan yang paling sedikit.

Pada kode dibawah ini digunakan untuk membuat diagram pie berdasarkan data pada variabel count_Parental_Education_Level:

1. plt.pie(): Membuat diagram pie dengan:
  - Nilai dari count_Parental_Education_Level sebagai ukuran.
  - Label berdasarkan indeksnya.
  - Menampilkan persentase pada tiap bagian dengan format %1.1f%%.
  - Memutar diagram mulai dari sudut 90 derajat (startangle=90).

2. plt.title(): Memberikan judul pada diagram pie.
3. plt.legend(): Menambahkan legenda di sisi kiri diagram.

4. plt.show(): Menampilkan diagram pie.
"""

plt.figure(figsize=(8, 6))
plt.pie(
    count_Parental_Education_Level,
    labels=count_Parental_Education_Level.index,
    autopct="%1.1f%%",
    startangle=90
)
plt.title(f"Pie Chart of {feature}")
plt.legend(title=feature, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.show()

"""12. Barplot duabelas Memeriksa Fitur Distance from Home"""

feature = categorical_features[11]
count_Distance_from_Home = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_Distance_from_Home = pd.DataFrame({"Jumlah Sampel": count_Distance_from_Home, "Persentase": percent.round(1)})
print(df_Distance_from_Home)
count_Distance_from_Home.plot(kind="bar", title=feature)
plt.xlabel("Distance from Home")
plt.show()

"""Mayoritas dalam sampel memiliki jarak rumah yang dekat dengan lokasi yang dianalisis, yaitu 59.6% dari total sampel. Sementara itu, sekitar 30.5% memiliki jarak yang sedang, dan hanya 9.9% yang memiliki jarak jauh.

Pada kode dibawah ini digunakan untuk membuat diagram pie berdasarkan data pada variabel count_Distance_from_Home:

1. plt.pie(): Membuat diagram pie dengan:
  - Nilai dari count_Distance_from_Home sebagai ukuran.
  - Label berdasarkan indeksnya.
  - Menampilkan persentase pada tiap bagian dengan format %1.1f%%.
  - Memutar diagram mulai dari sudut 90 derajat (startangle=90).

2. plt.title(): Memberikan judul pada diagram pie.
3. plt.legend(): Menambahkan legenda di sisi kiri diagram.

4. plt.show(): Menampilkan diagram pie.
"""

plt.figure(figsize=(8, 6))
plt.pie(
    count_Distance_from_Home,
    labels=count_Distance_from_Home.index,
    autopct="%1.1f%%",
    startangle=90
)
plt.title(f"Pie Chart of {feature}")
plt.legend(title=feature, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.show()

"""13. Barplot tigabelas Memeriksa Fitur Gender"""

feature = categorical_features[12]
count_Gender = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_Gender = pd.DataFrame({"Jumlah Sampel": count_Gender, "Persentase": percent.round(1)})
print(df_Gender)
count_Gender.plot(kind="bar", title=feature)
plt.xlabel("Gender")
plt.show()

"""jumlah pria lebih banyak dari jumlah perempuan.

Pada kode dibawah ini digunakan untuk membuat diagram pie berdasarkan data pada variabel count_Gender:

1. plt.pie(): Membuat diagram pie dengan:
  - Nilai dari count_Gender sebagai ukuran.
  - Label berdasarkan indeksnya.
  - Menampilkan persentase pada tiap bagian dengan format %1.1f%%.
  - Memutar diagram mulai dari sudut 90 derajat (startangle=90).

2. plt.title(): Memberikan judul pada diagram pie.
3. plt.legend(): Menambahkan legenda di sisi kiri diagram.

4. plt.show(): Menampilkan diagram pie.
"""

plt.figure(figsize=(8, 6))
plt.pie(
    count_Gender,
    labels=count_Gender.index,
    autopct="%1.1f%%",
    startangle=90
)
plt.title(f"Pie Chart of {feature}")
plt.legend(title=feature, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.show()

"""Saya juga menggunakan histogram untuk menganalisis data, karena grafik ini memudahkan saya melihat distribusi dan pola data dengan jelas, sehingga bisa menarik kesimpulan yang lebih tepat."""

df.hist(bins = 50, figsize = (20, 15))
plt.show()

"""Sebagian besar siswa belajar sekitar 15-25 jam per minggu, dengan distribusi waktu belajar yang menyerupai pola normal. Kehadiran siswa di kelas cukup merata, berada di kisaran 60-100 persen. Mayoritas siswa tidur 7-8 jam, sesuai dengan durasi tidur yang ideal. Nilai sebelumnya menunjukkan tren meningkat, dengan lonjakan signifikan pada nilai tertinggi (100). Banyak siswa tidak mengikuti sesi bimbingan belajar, tetapi bagi yang mengikuti, mereka cenderung menghadiri 1-3 sesi. Aktivitas fisik siswa didominasi oleh tingkat sedang, dengan puncak di tingkat aktivitas 3. Nilai ujian juga menunjukkan distribusi normal, dengan mayoritas siswa mendapatkan nilai rata-rata sekitar 68-70.

## B. MULTIVARIATE ANALYSIS

Kode dibawah ini membuat barplot untuk menampilkan rata-rata Exam_Score berdasarkan setiap kolom kategori. Data dikelompokkan, dihitung rata-ratanya, diurutkan, lalu divisualisasikan. Nilai rata-rata ditampilkan di atas batang, dengan judul, label sumbu, dan garis bantu untuk memperjelas informasi.
"""

cat_features = df.select_dtypes(include="object").columns.to_list()

for col in cat_features:
    agg_data = df.groupby(col)['Exam_Score'].mean().reset_index()
    agg_data = agg_data.sort_values(by='Exam_Score', ascending=False)

    plt.figure(figsize=(12, 6))
    sns.barplot(
        x=col, y="Exam_Score", data=df, palette="deep", ci=None,
        order=agg_data[col]
    )

    for i, row in agg_data.iterrows():
        plt.text(
            x=i,
            y=row['Exam_Score'] + 0.5,
            s=f"{row['Exam_Score']:.1f}",
            ha='center', va='center', fontsize=10, color='black'
        )

    plt.title(f"Rata-rata Exam Score ({df['Exam_Score'].mean():.2f}) berdasarkan {col}", fontsize=16)
    plt.xlabel(col, fontsize=14)
    plt.ylabel("Rata-rata Exam Score", fontsize=14)
    plt.xticks(rotation=45)
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.tight_layout()
    plt.show()

"""Dari bar plot diatas ini, dapat disimpulkan bahwa siswa dengan tingkat Access_to_Resources yang tinggi memiliki rata-rata Exam Score tertinggi sebesar 67.8. Hal ini menunjukkan bahwa ketersediaan sumber daya pendidikan yang tinggi cenderung memberikan dampak positif terhadap hasil ujian siswa.

Kode dibawah ini digunakan untuk membuat pairplot dengan Seaborn untuk melihat hubungan antara fitur numerik dalam dataset df. Diagonal grafik menampilkan distribusi data menggunakan Kernel Density Estimation (KDE). Visualisasi ini membantu memahami korelasi dan pola antar fitur secara lebih mudah.
"""

sns.pairplot(df, diag_kind = "kde")

"""Dari hasil pairplot, terlihat bahwa Hours_Studied dan Attendance adalah dua fitur numerik yang paling berkorelasi dengan Exam_Score. Oleh karena itu, kedua variabel ini dapat menjadi prediktor yang baik dalam model prediksi performa ujian.

Kode dibawah ini membuat *heatmap* untuk memvisualisasikan matriks korelasi fitur numerik dalam dataset. Nilai korelasi dihitung, dibulatkan, dan ditampilkan dengan anotasi menggunakan skema warna "coolwarm". Grafik ini mempermudah analisis hubungan antar fitur numerik.
"""

plt.figure(figsize = (10, 8))
correlation_matrix = df[numerical_features].corr().round(2)

sns.heatmap(data = correlation_matrix, annot = True, cmap = "coolwarm", linewidths = 0.5)
plt.title("Correlation Matrix untuk Fitur Numerik", size = 20)

"""Berdasarkan korelasi ini, Attendance (kehadiran) dan Hours_Studied (jam belajar) punya hubungan yang kuat dengan skor ujian, jadi ini adalah faktor penting yang memengaruhi hasil ujian. Sebaliknya, fitur seperti Sleep_Hours, Tutoring_Sessions, dan Physical_Activity hampir tidak ada hubungannya dengan skor, jadi mereka kurang relevan. Hubungan antar fitur juga lemah, jadi tidak ada fitur yang saling tumpang-tindih informasi di antaranya.

# 6. Data Preparation

Menghapus fitur yang memiliki korelasi rendah terhadap variabel target (Exam_Score) berdasarkan analisis korelasi sebelumnya.
"""

df.drop(["Physical_Activity", "Sleep_Hours"], inplace = True, axis = 1)
df.head()

"""A. Encoding fitur kategori

untuk mengubah data kategorikal menjadi format numerik menggunakan one-hot encoding, sehingga dapat digunakan oleh algoritma pembelajaran mesin.
"""

df = pd.concat([df, pd.get_dummies(df["Parental_Involvement"], prefix = "Parental_Involvement")],axis = 1)
df = pd.concat([df, pd.get_dummies(df["Access_to_Resources"], prefix = "Access_to_Resources")],axis = 1)
df = pd.concat([df, pd.get_dummies(df["Extracurricular_Activities"], prefix = "Extracurricular_Activities")],axis = 1)
df = pd.concat([df, pd.get_dummies(df["Motivation_Level"], prefix = "Motivation_Level")],axis = 1)
df = pd.concat([df, pd.get_dummies(df["Internet_Access"], prefix = "Internet_Access")],axis = 1)
df = pd.concat([df, pd.get_dummies(df["Family_Income"], prefix = "Family_Income")],axis = 1)
df = pd.concat([df, pd.get_dummies(df["Teacher_Quality"], prefix = "Teacher_Quality")],axis = 1)
df = pd.concat([df, pd.get_dummies(df["School_Type"], prefix = "School_Type")],axis = 1)
df = pd.concat([df, pd.get_dummies(df["Peer_Influence"], prefix = "Peer_Influence")],axis = 1)
df = pd.concat([df, pd.get_dummies(df["Learning_Disabilities"], prefix = "Learning_Disabilities")],axis = 1)
df = pd.concat([df, pd.get_dummies(df["Parental_Education_Level"], prefix = "Parental_Education_Level")],axis = 1)
df = pd.concat([df, pd.get_dummies(df["Distance_from_Home"], prefix = "Distance_from_Home")],axis = 1)
df = pd.concat([df, pd.get_dummies(df["Gender"], prefix = "Gender")],axis = 1)
df.drop(["Parental_Involvement", "Access_to_Resources", "Extracurricular_Activities", "Gender", "Motivation_Level", "Internet_Access", "Family_Income", "Teacher_Quality", "School_Type", "Peer_Influence", "Learning_Disabilities", "Parental_Education_Level", "Distance_from_Home", "Gender"], axis = 1, inplace = True)
df

"""Setelah dilakukan encoding terhadap fitur-fitur kategorikal menggunakan metode one-hot encoding, data berhasil dikonversi ke format numerik sehingga dapat digunakan dalam algoritma pembelajaran mesin. Proses ini menghasilkan tambahan kolom baru yang merepresentasikan setiap kategori dalam fitur aslinya, sementara kolom kategorikal asli dihapus dari dataset.

Sebagai hasil akhir, dataset sekarang memiliki 39 kolom yang mencakup fitur numerik asli dan hasil encoding. Total baris data setelah proses data cleaning adalah 5.836, yang siap digunakan untuk analisis lebih lanjut atau pembuatan model prediktif.

B. Reduksi Dimensi dengan PCA

PCA dilakukan untuk menggabungkan dua fitur utama, yaitu Attendance dan Hours_Studied, menjadi satu dimensi baru (dimension). Langkah ini bertujuan untuk mengurangi kompleksitas data dengan tetap mempertahankan informasi penting.
"""

sns.pairplot(df[["Attendance", "Hours_Studied"]], plot_kws = {"s": 2});

"""Hasilnya, dua fitur ini menunjukkan tidak adanya hubungan linear yang jelas antara Attendance (kehadiran) dan Hours_Studied (jam belajar), dengan sebaran data yang merata. Histogram Attendance memiliki distribusi seragam di kisaran 60-100, sementara Hours_Studied mengikuti distribusi normal dengan puncak di sekitar 20 jam. Kedua fitur ini memiliki pola distribusi yang berbeda, sehingga penting untuk memverifikasi efektivitas PCA jika digunakan untuk mengurangi dimensi data."""

from sklearn.decomposition import PCA

pca = PCA(n_components=2, random_state=123)
pca.fit(df[["Attendance", "Hours_Studied"]])
princ_comp = pca.transform(df[["Attendance", "Hours_Studied"]])

pca.explained_variance_ratio_.round(5)

"""Dengan PCA, dua fitur numerik (Attendance dan Hours_Studied) berhasil direduksi menjadi dua komponen utama tanpa kehilangan informasi penting. Komponen pertama menyimpan sebagian besar informasi (79.839%), sehingga sangat representatif, sedangkan komponen kedua melengkapi sisa variansi (20.161%). Teknik ini berguna untuk menyederhanakan analisis data sekaligus mempertahankan pola utama."""

pca = PCA(n_components = 1, random_state = 123)
pca.fit(df[["Attendance", "Hours_Studied"]])
df["dimension"] = pca.transform(df.loc[:,  ("Attendance", "Hours_Studied")]).flatten()
df.drop(["Attendance", "Hours_Studied"], axis = 1, inplace = True)

"""Kode diatas ini menggunakan PCA untuk menggabungkan dua fitur numerik (Attendance dan Hours_Studied) menjadi satu dimensi utama, yaitu kolom dimension. Transformasi ini dilakukan untuk menyederhanakan data sambil mempertahankan informasi inti yang paling signifikan. Kolom asli dihapus untuk mencegah duplikasi data.

C. Train-Test-Split
"""

from sklearn.model_selection import train_test_split
X = df.drop(["Exam_Score"],axis = 1)
y = df["Exam_Score"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

"""Langkah ini memisahkan dataset menjadi dua bagian:

X: Berisi semua kolom kecuali kolom target Exam_Score. Fitur-fitur ini akan digunakan untuk memprediksi nilai target.
y: Berisi kolom target Exam_Score, yang merupakan variabel yang ingin diprediksi oleh model.

- Data latih (X_train dan y_train): Digunakan untuk melatih model.
- Data uji (X_test dan y_test): Digunakan untuk mengevaluasi performa model.

Parameter test_size=0.1 berarti 10% data akan digunakan sebagai data uji, sementara 90% sisanya akan menjadi data latih.
Parameter random_state=123 digunakan agar pembagian data tetap konsisten setiap kali kode dijalankan.
"""

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""Kesimpulannya:
membagi dataset menjadi fitur (X) dan target (y), kemudian memisahkan data tersebut menjadi data latih dan data uji dengan rasio 90:10. Proses ini penting untuk memastikan model dapat dilatih dengan data latih dan diuji dengan data uji untuk mengevaluasi performanya pada data baru.

D. Standarisasi

StandardScaler dapat dijelaskan dengan rumus berikut:

$$z = \frac{x-u}{s}$$


di mana:

$z$: Nilai data yang sudah distandarisasi
$x$: Nilai data asli sebelum distandarisasi
$u$: Rata-rata dari seluruh data
$s$: Simpangan baku (standar deviasi) dari data
"""

from sklearn.preprocessing import StandardScaler

numerical_features = ["Tutoring_Sessions", "Previous_Scores", "dimension"]
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

"""Untuk menstandarkan fitur numerik seperti Tutoring_Sessions, Previous_Scores, dan dimension agar memiliki distribusi dengan rata-rata 0 dan standar deviasi 1"""

X_train[numerical_features].describe().round(4)

"""Hasilnya, fitur numerik telah dinormalisasi dengan statistik yang seragam, yaitu rata-rata 0 dan standar deviasi 1, yang meningkatkan konsistensi dan performa model."""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.metrics import mean_squared_error

models = pd.DataFrame(index = ["train_mse", "test_mse"],
                      columns = ["KNN", "RandomForest", "Boosting"])

"""Kode diatas ini mengimpor model regresi dan MSE, lalu membuat DataFrame untuk menyimpan hasil MSE dari data latih dan uji untuk setiap model.

# 7. Model Development

A. Model Development dengan K-Nearest Neighbor

n_neighbors=10: Parameter n_neighbors menentukan jumlah tetangga terdekat yang akan digunakan untuk menghitung prediksi. Dalam hal ini, model akan mencari 10 data pelatihan terdekat dari data yang akan diprediksi.
"""

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)
models.loc["train_mse","knn"] = mean_squared_error(y_pred = knn.predict(X_train), y_true = y_train)

"""B. Model Development dengan Random Forest

n_estimators=50: Menentukan jumlah pohon keputusan yang akan dibangun. Dalam hal ini, model akan menggunakan 50 pohon.
max_depth=16: Menentukan kedalaman maksimum dari setiap pohon. Ini mengontrol seberapa dalam pohon dapat tumbuh, yang berpengaruh pada kompleksitas model.
random_state=55: Menetapkan nilai acak untuk memastikan hasil yang dapat direproduksi setiap kali model dijalankan.
n_jobs=-1: Menggunakan semua inti prosesor yang tersedia untuk memparalelkan perhitungan, sehingga proses pelatihan menjadi lebih cepat.
"""

RF = RandomForestRegressor(n_estimators = 50, max_depth = 16, random_state = 55, n_jobs = -1)
RF.fit(X_train, y_train)
models.loc["train_mse", "RandomForest"] = mean_squared_error(y_pred = RF.predict(X_train), y_true = y_train)

"""C. Model Development dengan Boosting Algorithm

Learning_rate=0.05: Parameter ini mengontrol seberapa besar kontribusi setiap model baru terhadap prediksi keseluruhan. Dengan nilai 0.05, model baru akan memiliki kontribusi yang lebih kecil dalam perbaikan kesalahan model sebelumnya.
random_state=55: Sama seperti pada Random Forest, ini digunakan untuk memastikan hasil yang konsisten saat kode dijalankan berulang kali.
"""

boosting = AdaBoostRegressor(learning_rate = 0.05, random_state = 55)
boosting.fit(X_train, y_train)
models.loc["train_mse", "Boosting"] = mean_squared_error(y_pred = boosting.predict(X_train), y_true = y_train)

"""# 8. Evaluasi Model

Untuk evaluasi model, kita dapat menggunakan Mean Squared Error (MSE), yang dirumuskan sebagai:
$$MSE = \frac{\Sigma (y_i - \hat{y_i})^2}{n}$$
dengan
* $y_i$: Nilai y sesungguhnya
* $\hat{y_i}$: Nilai y prediksi
* $n$: Jumlah data

Selain MSE, evaluasi juga dapat dilakukan menggunakan Root Mean Squared Error (RMSE). RMSE merupakan akar dari MSE, sehingga rumusnya adalah:
$$RMSE = \sqrt{MSE} = \sqrt{\frac{\Sigma (y_i - \hat{y_i})^2}{n}}$$

Selain kedua metrik tersebut, ada juga Mean Absolute Error (MAE). MAE dihitung dengan rumus:
$$MAE = \frac{\Sigma |y_i - \hat{y_i|}}{n}$$

Kode dibawah ini melakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
"""

X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""Kode dibawah ini menghitung Mean Squared Error (MSE) untuk model KNN, Random Forest (RF), dan Boosting pada data latih dan uji."""

mse = pd.DataFrame(columns = ["train", "test"], index = ["KNN", "RF", "Boosting"])

model_dict = {"KNN": knn, "RF": RF, "Boosting": boosting}

for name, model in model_dict.items():
    mse.loc[name, "train"] = mean_squared_error(y_true = y_train, y_pred = model.predict(X_train))
    mse.loc[name, "test"] = mean_squared_error(y_true = y_test, y_pred = model.predict(X_test))

mse

"""Hasilnya menunjukkan bahwa RF memiliki performa terbaik dengan MSE rendah (0.515514 pada data latih dan 3.288766 pada data uji), sementara Boosting memiliki MSE tertinggi dan kurang optimal. KNN cukup baik tetapi masih kalah dari RF.

Kode di bawah ini menghitung Mean Squared Error (MSE) untuk tiga model prediksi (KNN, Random Forest, dan Boosting) pada data latih (train) dan uji (test). Dua metode digunakan untuk menghitung MSE: fungsi bawaan mean_squared_error dan fungsi kustom MSE
"""

def MSE(y_true, y_test):
    sum_error = 0.0
    y_true_values = y_true.values
    y_test_values = y_test

    if not isinstance(y_test_values, np.ndarray):
        y_test_values = np.array(y_test_values)

    for i in range(min(len(y_true_values), len(y_test_values))):
        prediction_error =  y_true_values[i] - y_test_values[i]
        sum_error += (prediction_error ** 2)
    mean_error = sum_error / float(min(len(y_true_values), len(y_test_values)))
    return mean_error

mse_2 = pd.DataFrame(columns = ["train", "test"], index = ["KNN", "RF", "Boosting"])

for name, model in model_dict.items():
    mse_2.loc[name, "train"] = MSE(y_train, model.predict(X_train))
    mse_2.loc[name, "test"] = MSE(y_test, model.predict(X_test))

mse_2

"""Hasilnya sama, menunjukkan konsistensi penghitungan.

Hasil menunjukkan:

KNN: MSE moderat untuk latih (3.662) dan uji (4.271), menunjukkan keseimbangan performa.

Random Forest: MSE terendah pada data uji (3.289), menunjukkan performa terbaik, meski ada sedikit overfitting.

Boosting: MSE tertinggi pada latih (4.938) dan uji (5.136), menunjukkan performa paling lemah.

Kesimpulannya, Random Forest adalah model terbaik untuk data ini.

Kode di bawah ini menghitung Root Mean Squared Error (RMSE) untuk tiga model prediksi (KNN, Random Forest, dan Boosting) pada data latih (train) dan uji (test). Fungsi kustom RMSE dibuat dengan cara menghitung akar kuadrat dari rata-rata kesalahan kuadrat antara nilai sebenarnya (y_true) dan prediksi (y_test). Hasil RMSE disimpan dalam tabel untuk setiap model dan data.
"""

def RMSE(y_true, y_test):
    sum_error = 0.0
    y_true_values = y_true.values
    y_test_values = y_test

    if not isinstance(y_test_values, np.ndarray):
        y_test_values = np.array(y_test_values)

    for i in range(min(len(y_true_values), len(y_test_values))):
        prediction_error =  y_true_values[i] - y_test_values[i]
        sum_error += (prediction_error ** 2)
    mean_error = np.sqrt(sum_error / float(min(len(y_true_values), len(y_test_values))))
    return mean_error

rmse = pd.DataFrame(columns = ["train", "test"], index = ["KNN", "RF", "Boosting"])

for name, model in model_dict.items():
    rmse.loc[name, "train"] = RMSE(y_train, model.predict(X_train))
    rmse.loc[name, "test"] = RMSE(y_test, model.predict(X_test))

rmse

"""Hasil:

KNN: RMSE moderat pada latih (1.914) dan uji (2.067), menunjukkan performa stabil.

Random Forest: RMSE terendah pada uji (1.813), mengindikasikan performa terbaik dengan sedikit overfitting.

Boosting: RMSE tertinggi pada latih (2.222) dan uji (2.266), mengindikasikan performa kurang optimal.

Kesimpulan: Random Forest memiliki performa terbaik, diikuti oleh KNN. Boosting memberikan hasil terburuk pada data ini.

Kode dibawah ini menghitung Mean Absolute Error (MAE) untuk tiga model prediksi (KNN, Random Forest, dan Boosting) pada data latih (train) dan uji (test). Fungsi MAE mengakumulasi rata-rata dari selisih absolut antara nilai sebenarnya (y_true) dan nilai prediksi (y_test). Hasilnya disusun dalam tabel untuk setiap model.
"""

def MAE(y_true, y_test):
    sum_error = 0.0
    y_true_values = y_true.values
    y_test_values = y_test

    if not isinstance(y_test_values, np.ndarray):
        y_test_values = np.array(y_test_values)

    for i in range(min(len(y_true_values), len(y_test_values))):
        prediction_error =  y_true_values[i] - y_test_values[i]
        sum_error += np.abs(prediction_error)
    mean_error = sum_error / float(min(len(y_true_values), len(y_test_values)))
    return mean_error

mae = pd.DataFrame(columns = ["train", "test"], index = ["KNN", "RF", "Boosting"])

for name, model in model_dict.items():
    mae.loc[name, "train"] = MAE(y_train, model.predict(X_train))
    mae.loc[name, "test"] = MAE(y_test, model.predict(X_test))

mae

"""Hasil:

KNN: MAE pada latih (1.537) dan uji (1.670) relatif stabil.

Random Forest: MAE terendah pada uji (1.458), menunjukkan performa terbaik dan prediksi yang lebih akurat.

Boosting: MAE tertinggi pada latih (1.786) dan uji (1.807), mengindikasikan performa kurang optimal dibandingkan model lainnya.

Kesimpulan: Random Forest memberikan hasil terbaik dalam hal kesalahan absolut, diikuti oleh KNN, sedangkan Boosting menunjukkan performa terburuk pada data ini.

Kode dibawah ini membuat diagram batang horizontal untuk membandingkan MSE (Mean Squared Error) tiga model (KNN, RF, Boosting) pada data uji. Diagram diurutkan berdasarkan MSE tertinggi di atas, dengan grid di belakang grafik.
"""

fig, ax = plt.subplots()
mse.sort_values(by = "test", ascending = False).plot(kind = "barh", ax = ax, zorder = 3)
ax.grid(zorder = 0)

"""Bisa dilihat algoritma Random Forest memiliki nilai error yang paling kecil."""

prediksi = X_test.iloc[:5].copy()
pred_dict = {'y_true':y_test[:5]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Berdasarkan hasil prediksi untuk 5 sampel pertama pada data uji, dapat dilihat perbandingan antara nilai sebenarnya (y_true) dan prediksi dari masing-masing model:

*   KNN cenderung memiliki prediksi yang lebih sedikit lebih rendah dibandingkan nilai sebenarnya (y_true).
*   Random Forest menghasilkan prediksi yang lebih akurat dengan sedikit dari nilai sebenarnya, meskipun sedikit lebih rendah pada beberapa sampel.
*   Boosting memberikan prediksi yang sedikit lebih rendah atau lebih jauh dari nilai yang sebenarnya dibandingkan dengan RF, meskipun hasilnya masih cukup dekat.

Kesimpulannya:  

1.   Model yang paling akurat: Berdasarkan hasil prediksi, Random Forest (RF) adalah model yang paling akurat untuk memprediksi nilai ujian (Exam_Score) dibandingkan dengan KNN dan Boosting, karena prediksinya lebih dekat dengan nilai asli (y_true).

2.   Menjawab Business Understanding: Dalam konteks Business Understanding yang bertujuan untuk memprediksi nilai ujian siswa (Exam_Score), model RF lebih sesuai untuk tujuan ini karena memberikan prediksi yang lebih konsisten dan akurat. Random Forest adalah model yang terbaik dalam kasus ini, karena prediksi yang lebih dekat dengan nilai sebenarnya.
"""